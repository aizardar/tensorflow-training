{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a BERT model for text extraction with the SQuAD dataset\n",
    "\n",
    "We are going to fine-tune BERT for the text-extraction task with a dataset of questions and answers. The question are about a give paragraph (*context*) that contains the answers. The model will be trained to locate the answer in the context by giving the possitions where the answer starts and finishes.\n",
    "\n",
    "This notebook is based on [BERT (from HuggingFace Transformers) for Text Extraction](https://keras.io/examples/nlp/text_extraction_with_bert/).\n",
    "\n",
    " More info:\n",
    "  * [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import dataset_utils as du\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "max_len = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",\n",
    "                                               cache_dir=f\"/scratch/snx3000/stud50/_bert_tockenizer\")\n",
    "\n",
    "save_path = f\"/scratch/snx3000/stud50/bert_tockenizer\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(f\"{save_path}/vocab.txt\", lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n",
    "train_path = keras.utils.get_file(\"train.json\", train_data_url, cache_dir=\"./\")\n",
    "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url, cache_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 training items loaded.\n",
      "48 evaluation items loaded.\n"
     ]
    }
   ],
   "source": [
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)\n",
    "\n",
    "print(f\"{len(raw_train_data['data'])} training items loaded.\")\n",
    "print(f\"{len(raw_eval_data['data'])} evaluation items loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86136 training points created.\n",
      "10331 evaluation points created.\n",
      "CPU times: user 54.7 s, sys: 1.37 s, total: 56.1 s\n",
      "Wall time: 56.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_squad_examples = du.create_squad_examples(raw_train_data, max_len, tokenizer)\n",
    "x_train, y_train = du.create_inputs_targets(train_squad_examples, shuffle=True, seed=42)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "\n",
    "eval_squad_examples = du.create_squad_examples(raw_eval_data, max_len, tokenizer)\n",
    "x_eval, y_eval = du.create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "encoder = TFBertModel.from_pretrained(\"bert-base-uncased\",\n",
    "                                      cache_dir=f\"/scratch/snx3000/stud50/bert_model\")\n",
    "\n",
    "input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "\n",
    "embedding = encoder(input_ids,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    attention_mask=attention_mask)[0]\n",
    "\n",
    "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
    "start_logits = layers.Flatten()(start_logits)\n",
    "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
    "\n",
    "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
    "end_logits = layers.Flatten()(end_logits)\n",
    "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
    "\n",
    "model = keras.Model(inputs=[input_ids, token_type_ids, attention_mask],\n",
    "                    outputs=[start_probs, end_probs])\n",
    "\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(lr=5e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 384, 768), ( 109482240   input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_logit (Dense)             (None, 384, 1)       768         tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "end_logit (Dense)               (None, 384, 1)       768         tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 384)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 384)          0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,776\n",
      "Trainable params: 109,483,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([16, 384]), TensorShape([16, 384]), TensorShape([16, 384])] [TensorShape([16]), TensorShape([16])]\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(x, y, batch_size=batch_size):\n",
    "    dataset = tf.data.Dataset.zip((\n",
    "        tf.data.Dataset.from_tensor_slices(x),\n",
    "        tf.data.Dataset.from_tensor_slices(y),\n",
    "    ))\n",
    "    dataset = dataset.shuffle(2048, seed=42)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# batch shapes\n",
    "for X, Y in get_dataset(x_train, y_train).take(1):\n",
    "    print([i.shape for i in X],\n",
    "          [i.shape for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def dataset_generator(x, y):\n",
    "#     for i in range(x[0].shape[0]):\n",
    "#         yield ((x[0][i], x[1][i], x[2][i]),\n",
    "#                (y[0][i], y[1][i]))\n",
    "\n",
    "# def get_generator(x, y, batch_size=batch_size, output_shapes=(((max_len,), (max_len,), (max_len,)),((), ()))):\n",
    "#     dataset = tf.data.Dataset.from_generator(lambda: dataset_generator(x, y),\n",
    "#                                              output_types=((tf.int32, tf.int32, tf.int32),(tf.int32, tf.int32)),\n",
    "#                                              output_shapes=output_shapes)\n",
    "#     dataset = dataset.shuffle(2048, seed=42)\n",
    "#     dataset = dataset.repeat()\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     return dataset\n",
    "\n",
    "# # batch shapes\n",
    "# for X, Y in get_generator(x_train, y_train).take(1):\n",
    "#     print([i.shape for i in X],\n",
    "#           [i.shape for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "50/50 [==============================] - 203s 4s/step - loss: 7.5988 - activation_12_loss: 3.8840 - activation_13_loss: 3.7147 - activation_12_accuracy: 0.1400 - activation_13_accuracy: 0.1338 - val_loss: 5.1783 - val_activation_12_loss: 2.6250 - val_activation_13_loss: 2.5533 - val_activation_12_accuracy: 0.3422 - val_activation_13_accuracy: 0.3471\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(get_dataset(x_train, y_train),\n",
    "                epochs=1,\n",
    "                steps_per_epoch=50,\n",
    "                validation_data=get_dataset(x_eval, y_eval),\n",
    "                validation_steps=len(y_eval[0]) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(f\"{os.environ['SCRATCH']}/bert_model_tuned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    exclude = set(string.punctuation)\n",
    "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    # Remove articles\n",
    "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "    text = re.sub(regex, \" \", text)\n",
    "\n",
    "    # Remove extra white space\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "class ExactMatch():\n",
    "    \"\"\"\n",
    "    Each `SquadExample` object contains the character level offsets for each token\n",
    "    in its input paragraph. We use them to get back the span of text corresponding\n",
    "    to the tokens between our predicted start and end tokens.\n",
    "    All the ground-truth answers are also present in each `SquadExample` object.\n",
    "    We calculate the percentage of data points where the span of text obtained\n",
    "    from model predictions matches one of the ground-truth answers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_eval, y_eval, model, squad_examples):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "        self.model = model\n",
    "        self.squad_examples = squad_examples\n",
    "\n",
    "    def score(self, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in self.squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "\n",
    "            normalized_pred_ans = normalize_text(pred_ans)\n",
    "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "                \n",
    "            print(f'  - {normalized_pred_ans:30.30s} | ref: {squad_eg.answer_text:30s} | {squad_eg.question}')\n",
    "\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 1870 to 1939                   | ref: 1870 to 1939                   | How long was the Summer Theatre in operation?\n",
      "  -                                | ref: extra-legal                    | Excessive bureaucratic red tape is one of the reasons for what type of ownership?\n",
      "  - paramount pictures and would l | ref: Paramount Pictures             | What company did Eisner become president of when he left ABC in 1976?\n",
      "  -                                | ref: 300 km long                    | How long is the Upper Rhine Plain?\n",
      "  - 1346 and 1671                  | ref: the plague was present somewhere in Europe in every year between 1346 and 1671. | What did Biraben say about the plague in Europe?\n",
      "  - luna 180foot 55 mtall 600yearo | ref: 738 days                       | How long did Julia Butterfly Hill live in a tree?\n",
      "  - elder brother alexander i had  | ref: Sybilla of Normandy            | Who did Alexander I marry?\n",
      "  - wireless controlled boat       | ref: boat                           | What remote control vehicle did he make?\n",
      "  -                                | ref: TARDIS                         | What is Doctor Who's space ship called?\n",
      "  - adaptive immune system         | ref: Trypanosoma brucei             | What is an example of a parasite that used the antigenic variation strategy to evade destruction?\n",
      "  -                                | ref: Gian Lorenzo Bernini           | Which Italian that is credited with the creating the Baroque style of sculpture is represented in the V&A's British galleries?\n",
      "  - kingdom of qocho and tibetan i | ref: through Kingdom of Qocho and Tibetan intermediaries | How did the Mongols acquire Chinese printing technology?\n",
      "  - st bartholomews day massacre   | ref: St. Bartholomew's Day massacre | What event was the worst example of Huguenot persecution?\n",
      "  - 15 saturn v rockets 16 command | ref: 15                             | How many Saturn V rockets were produced by NASA during the Apollo project?\n",
      "  - 1850                           | ref: 1850                           | When did France begin in earnest to rebuild its global empire?\n",
      "  - david graeber and donald johan | ref: David Graeber and Donald Johanson | What anthropologists are also university alumni members?\n",
      "  - may 18 1756                    | ref: May 18, 1756                   | When did England formally declare war on France?\n",
      "  - accrediting teacher education  | ref: teacher's colleges             | Who might take disciplinary action against a teacher?\n",
      "  - anglocatholic and reformed the | ref: Book of Discipline             | What states that United Methodist theology is at once \"catholic, evangelical and reformed?\"\n",
      "  -                                | ref: glaucophyte chloroplasts       | What are muroplasts?\n",
      "  - low total pressures            | ref: no damage                      | How much damage does breathing oxygen in space conditions cause?\n",
      "  - dan fouts                      | ref: Boomer Esiason and Dan Fouts   | Who were the Westwood one color analysts?\n",
      "  - top 15                         | ref: 15                             | What is the lowest ranking one of the counties could have in terms of most populous counties in the United States?\n",
      "  - high pressure                  | ref: DC                             | What type of electric current is needed for electrolysis?\n",
      "  -                                | ref: keeping it from folding prematurely | What is the benefit of polypeptide binding?\n",
      "  -                                | ref: September 8, 2007              | When was ABC1 discontinued because of low viewership?\n",
      "  -                                | ref: Business Connect               | What is the name of the program that provides contracting work to local companies?\n",
      "  - coteaching focuses student on  | ref: learning                       | What does co-teaching get the students to focus on?\n",
      "  - shetland and western isles     | ref: dispersed population and distance | Why do the island archipelagos comprise a smaller number of electors?\n",
      "  - 1835 and 1842                  | ref: between 1835 and 1842          | When was Richard Grainger actively building and developing?\n",
      "  - power outage                   | ref: power outage                   | What did Tesla accidentally cause?\n",
      "  - innate leukocytes include phag | ref: macrophages, neutrophils, and dendritic cells | What are three kinds of phagocytes?\n",
      "  -                                | ref: 12 May 1705                    | When were these settlers naturalized as English colonists?\n",
      "  - sweden has made progress in us | ref: 8.8                            | How many pounds of steam per kilowatt hour does the Energiprojekt AB engine use?\n",
      "  -                                | ref: ambiguous                      | If you do not know both magnitude and direction of two forces on an object, what would you call that situation?\n",
      "  - 2011 cancellation of supernann | ref: 2011                           | In what year was Supernanny canceled?\n",
      "  - high and persistent unemployme | ref: subsequent long-run economic growth | What was persistent unemployment have a negative effect on?\n",
      "  - mannings hand as he was windin | ref: Devin Funchess                 | Who caught a 16-yard pass on this drive?\n",
      "  - archeologist betty meggers was | ref: Amazonia: Man and Culture in a Counterfeit Paradise | In what book did Betty Meggers describe the idea of the Amazon being sparsely populated?\n",
      "  - ncaas division iii             | ref: NCAA's Division III            | The Maroons compete in what league division?\n",
      "  -                                | ref: black-and-yellow               | What colors was the 2001 ABC logo?\n",
      "  - annual status of education rep | ref: evaluates learning levels in rural India | What is the purpose of the ASER?\n",
      "  - san francisco                  | ref: San Francisco                  | In what city is the Moscone Center located?\n",
      "  - complexity classes             | ref: complexity classes             | Bounding of time and space or similar measurements is often used by algorithms to define what?\n",
      "  -                                | ref: progressive tax                | What is it called when the tax rate and base amount increase simultaneously?\n",
      "  - decision time                  | ref: \"Decision Time\"                | What is heralded by the sounding of the division bell?\n",
      "  - force is required to maintain  | ref: fundamental error              | What was the belief that maintaining motion required force?\n",
      "  - labor                          | ref: National Party                 | Which party is strongest in Victoria's northwestern and eastern regions?\n",
      "  - september 30 1960              | ref: September 30, 1960             | When did ABC premier the Flintstones?\n",
      "  - nicholas stone caius gabriel c | ref: Europeans who were based in Britain | What sort of continental sculptors are represented in the British Galleries of the V&A?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.random.choice(len(x_eval[0]), 50, replace=False)\n",
    "\n",
    "em = ExactMatch([x_eval[0][samples], x_eval[1][samples], x_eval[2][samples]],\n",
    "                [y_eval[0][samples], y_eval[1][samples]],\n",
    "                model,\n",
    "                eval_squad_examples[samples])\n",
    "em.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model structure from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install --user torch\n",
    "from transformers.modeling_bert import BertModel\n",
    "BertModel.from_pretrained(\"bert-base-uncased\", cache_dir=os.environ['SCRATCH']+'/bert_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
